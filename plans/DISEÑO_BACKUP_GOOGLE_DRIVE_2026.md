# üõ°Ô∏è Dise√±o de Sistema de Backup - LAVAPP SaaS Multitenant

**Fecha**: 2026-02-09  
**Estado**: Dise√±o t√©cnico  
**Sistema**: LAVAPP SaaS (Postgres en Neon + Vercel)

---

## üéØ Objetivo

Backup completo y restaurable del sistema SaaS multitenant sin modificar el schema ni la l√≥gica existente.

### Requisitos
- ‚úÖ Backup completo (schema + datos)
- ‚úÖ Almacenamiento externo (Google Drive)
- ‚úÖ Independiente de Neon y Vercel
- ‚úÖ Restaurable en un branch nuevo de Neon
- ‚úÖ Sin modificar schema existente
- ‚úÖ Sin agregar soft delete ni auditor√≠a
- ‚úÖ Sin cambiar queries

---

## üèóÔ∏è 1. Arquitectura de Backup

### Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LAVAPP SaaS Architecture                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ Vercel App   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Neon Postgres   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ (Frontend +  ‚îÇ         ‚îÇ                 ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  Backend)    ‚îÇ         ‚îÇ - Branch Central‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ - Branch Lavapp ‚îÇ               ‚îÇ
‚îÇ                           ‚îÇ - Branch Demos  ‚îÇ               ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                    ‚îÇ                         ‚îÇ
‚îÇ                                    ‚îÇ pg_dump                ‚îÇ
‚îÇ                                    ‚ñº                         ‚îÇ
‚îÇ                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ                           ‚îÇ Backup Script  ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ  (Node.js)     ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ                ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ - pg_dump exec ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ - Compression  ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ - Encryption   ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ - Upload       ‚îÇ                ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                                    ‚îÇ                         ‚îÇ
‚îÇ                                    ‚îÇ HTTPS                   ‚îÇ
‚îÇ                                    ‚ñº                         ‚îÇ
‚îÇ                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ                           ‚îÇ Google Drive   ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ   API v3       ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ                ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ /backups/      ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ   ‚îî‚îÄ central/  ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ   ‚îî‚îÄ lavapp/   ‚îÇ                ‚îÇ
‚îÇ                           ‚îÇ   ‚îî‚îÄ demos/    ‚îÇ                ‚îÇ
‚îÇ                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack Tecnol√≥gico

| Componente | Herramienta | Justificaci√≥n |
|------------|-------------|---------------|
| **Export** | `pg_dump` (CLI) | Est√°ndar de PostgreSQL, formato compatible |
| **Runtime** | Node.js script | Integraci√≥n con ecosystem existente |
| **Compresi√≥n** | Custom format (built-in) | Compresi√≥n incluida en pg_dump, ~70% reducci√≥n |
| **Encriptaci√≥n** | AES-256-CBC (openssl) | Proteger datos sensibles, est√°ndar de la industria |
| **Storage** | Google Drive API v3 | 15GB gratis, versionado autom√°tico |
| **Scheduling** | GitHub Actions | Robusto, logs persistentes, no depende de Vercel |
| **Restore** | `pg_restore` + script Node.js | Est√°ndar PostgreSQL |

---

## üì¶ 2. Formato de Backup Recomendado

### Formato Principal: `pg_dump` Custom Format

**Comando**:
```bash
pg_dump \
  --format=custom \
  --compress=9 \
  --no-owner \
  --no-privileges \
  --clean \
  --if-exists \
  --verbose \
  "$DATABASE_URL" \
  --file="backup.dump"

# Luego encriptar (sin gzip adicional)
openssl enc -aes-256-cbc -salt \
  -in backup.dump \
  -out backup.dump.enc \
  -pass pass:$BACKUP_ENCRYPTION_KEY
```

**Caracter√≠sticas**:
- ‚úÖ **Custom format** (`.dump`): Flexible, comprimido, selectivo para restore
- ‚úÖ **Compress=9**: M√°xima compresi√≥n (~70% reducci√≥n) ya incluida
- ‚úÖ **--clean**: Incluye DROP commands para restore limpio
- ‚úÖ **--if-exists**: Evita errores si objetos no existen
- ‚úÖ **--no-owner**: Evita problemas de permisos en restore
- ‚úÖ **--verbose**: Logging detallado
- ‚úÖ **AES-256 solo**: No necesita gzip adicional, m√°s simple

**Nota**: El formato custom ya incluye compresi√≥n interna, por lo que NO se necesita `gzip` adicional. Solo aplicar encriptaci√≥n AES-256.

### Estructura de Archivos en Google Drive

```
/LAVAPP_Backups/
‚îú‚îÄ central/
‚îÇ  ‚îú‚îÄ 2026-02/
‚îÇ  ‚îÇ  ‚îú‚îÄ central_2026-02-09_00-00.dump.enc
‚îÇ  ‚îÇ  ‚îú‚îÄ central_2026-02-09_00-00.metadata.json
‚îÇ  ‚îÇ  ‚îú‚îÄ central_2026-02-08_00-00.dump.enc
‚îÇ  ‚îÇ  ‚îî‚îÄ ...
‚îÇ  ‚îî‚îÄ 2026-01/
‚îÇ     ‚îî‚îÄ ...
‚îÇ
‚îú‚îÄ lavapp/
‚îÇ  ‚îú‚îÄ 2026-02/
‚îÇ  ‚îÇ  ‚îú‚îÄ lavapp_2026-02-09_00-00.dump.enc
‚îÇ  ‚îÇ  ‚îú‚îÄ lavapp_2026-02-09_00-00.metadata.json
‚îÇ  ‚îÇ  ‚îî‚îÄ ...
‚îÇ  ‚îî‚îÄ 2026-01/
‚îÇ
‚îú‚îÄ demos/
‚îÇ  ‚îî‚îÄ (similar structure)
‚îÇ
‚îî‚îÄ README.md (instrucciones de restore)
```

**Nota**: Extensi√≥n `.dump.enc` (no `.dump.gz.enc`) porque el custom format ya est√° comprimido.

### Metadata JSON

Cada backup tiene un archivo metadata:

```json
{
  "backup_id": "lavapp_2026-02-09_00-00",
  "branch": "lavapp",
  "timestamp": "2026-02-09T03:00:00Z",
  "database_name": "neondb",
  "database_version": "PostgreSQL 16.1",
  "schema_version": "1.0.0",
  "backup_size_bytes": 15728640,
  "backup_size_compressed": 3145728,
  "compression_ratio": 0.20,
  "tables": [
    { "name": "registros_lavado", "row_count": 1523 },
    { "name": "clientes", "row_count": 234 },
    { "name": "usuarios", "row_count": 5 }
  ],
  "backup_duration_seconds": 12,
  "encrypted": true,
  "encryption_algorithm": "aes-256-cbc",
  "checksum_sha256": "abc123...",
  "script_version": "1.0.0"
}
```

---

## ‚è∞ 3. Frecuencia y Pol√≠tica de Retenci√≥n

### Estrategia 3-2-1

- **3** copias de datos (producci√≥n + 2 backups)
- **2** formatos/ubicaciones diferentes
- **1** copia offsite (Google Drive)

### Frecuencia de Backups

| Tipo | Frecuencia | Hora (UTC-3) | Retenci√≥n |
|------|------------|--------------|-----------|
| **Full Backup** | Diario | 03:00 AM | 30 d√≠as |
| **Weekly Snapshot** | Semanal (Domingo) | 02:00 AM | 3 meses |
| **Monthly Archive** | Mensual (d√≠a 1) | 01:00 AM | 1 a√±o |

### Pol√≠tica de Retenci√≥n Detallada

```javascript
// Pseudo-c√≥digo de retenci√≥n
const retentionPolicy = {
  daily: {
    keep: 30,        // √öltimos 30 d√≠as
    deleteAfter: 30  // Borrar despu√©s de 30 d√≠as
  },
  weekly: {
    keep: 12,        // √öltimas 12 semanas = 3 meses
    deleteAfter: 90  // Borrar despu√©s de 90 d√≠as
  },
  monthly: {
    keep: 12,        // √öltimos 12 meses = 1 a√±o
    deleteAfter: 365 // Borrar despu√©s de 1 a√±o
  }
};
```

### Rotaci√≥n Autom√°tica

**Ejemplo**: Si hoy es 10 de marzo:
- ‚úÖ Mantener: Todos los backups diarios desde 9 feb hasta hoy (30 d√≠as)
- ‚úÖ Mantener: Backups semanales desde diciembre (12 semanas)
- ‚úÖ Mantener: Backups mensuales desde marzo 2025 (12 meses)
- ‚ùå Eliminar: Backups diarios de antes del 9 de febrero
- ‚ùå Eliminar: Backups semanales de antes de diciembre
- ‚ùå Eliminar: Backups mensuales de antes de marzo 2025

### Espacio Estimado en Google Drive

| Branch | Tama√±o BD (sin compress) | Comprimido (20%) | Por 30 d√≠as | Por 3 meses |
|--------|-------------------------|------------------|-------------|-------------|
| central | ~50 MB | ~10 MB | 300 MB | 900 MB |
| lavapp | ~100 MB | ~20 MB | 600 MB | 1.8 GB |
| demos | ~20 MB | ~4 MB | 120 MB | 360 MB |
| **TOTAL** | - | ~34 MB/d√≠a | **1 GB** | **3 GB** |

**Conclusi√≥n**: Con 15 GB gratis en Google Drive, ten√©s espacio para **4-5 a√±os** de backups.

---

## üîß 4. Procedimiento de Restore Seguro en Branch

### Flujo de Restauraci√≥n

```
1. Descargar backup de Google Drive
        ‚Üì
2. Desencriptar y descomprimir
        ‚Üì
3. Crear nuevo branch en Neon (restore-YYYY-MM-DD)
        ‚Üì
4. Obtener connection string del nuevo branch
        ‚Üì
5. Ejecutar pg_restore en el nuevo branch
        ‚Üì
6. Validar datos restaurados (checksums, counts)
        ‚Üì
7. Si OK ‚Üí Promover branch a producci√≥n
   Si ERROR ‚Üí Eliminar branch y reintentar
```

### Script de Restore (Pseudoc√≥digo)

```javascript
// scripts/restore-backup.js

const restoreBackup = async (options) => {
  const {
    backupId,           // "lavapp_2026-02-09_00-00"
    targetBranch,       // Nuevo branch de Neon
    validateOnly        // Solo validar sin aplicar
  } = options;

  console.log(`üîÑ Iniciando restore de ${backupId}`);

  // 1. Descargar desde Google Drive
  const backupFile = await downloadFromDrive(backupId);
  console.log(`‚úÖ Descargado: ${backupFile}`);

  // 2. Desencriptar
  const decrypted = await decrypt(backupFile, process.env.BACKUP_ENCRYPTION_KEY);
  console.log(`‚úÖ Desencriptado`);

  // 3. Verificar checksum
  const metadata = await readMetadata(backupId);
  const checksum = await calculateSHA256(decrypted);
  if (checksum !== metadata.checksum_sha256) {
    throw new Error('‚ùå Checksum mismatch - archivo corrupto');
  }
  console.log(`‚úÖ Checksum verificado`);

  // 4. Crear branch de Neon para restore
  const restoreBranch = await createNeonBranch({
    name: `restore-${backupId}`,
    parent: 'main' // Branch vac√≠o
  });
  console.log(`‚úÖ Branch creado: ${restoreBranch.id}`);

  // 5. Esperar que branch est√© listo
  await waitForBranchReady(restoreBranch.id);

  // 6. Obtener connection string
  const connectionString = restoreBranch.connection_uri;

  // 7. Ejecutar pg_restore
  if (!validateOnly) {
    await execPromise(`
      pg_restore \
        --dbname="${connectionString}" \
        --verbose \
        --clean \
        --if-exists \
        --no-owner \
        --no-privileges \
        ${decrypted}
    `);
    console.log(`‚úÖ Restore completado en branch ${restoreBranch.id}`);
  }

  // 8. Validar datos restaurados
  const validation = await validateRestoredData(connectionString, metadata);
  
  if (validation.success) {
    console.log(`‚úÖ Validaci√≥n exitosa`);
    console.log(`üìä Tablas: ${validation.tableCount}`);
    console.log(`üìä Registros: ${validation.totalRows}`);
    return { success: true, branch: restoreBranch };
  } else {
    console.error(`‚ùå Validaci√≥n fall√≥: ${validation.errors}`);
    if (!validateOnly) {
      await deleteNeonBranch(restoreBranch.id);
      console.log(`üóëÔ∏è Branch de restore eliminado`);
    }
    return { success: false, errors: validation.errors };
  }
};
```

### Comandos Manuales de Restore

**Opci√≥n 1: Restore completo (Custom format)**

```bash
# 1. Descargar y desencriptar
openssl enc -d -aes-256-cbc -in backup.dump.gz.enc -out backup.dump.gz \
  -pass pass:$BACKUP_KEY
gunzip backup.dump.gz

# 2. Crear branch de Neon (manual en UI o via API)
# Obtener connection string del nuevo branch

# 3. Restaurar
pg_restore \
  --dbname="$RESTORE_CONNECTION_STRING" \
  --verbose \
  --clean \
  --if-exists \
  --no-owner \
  --no-privileges \
  backup.dump

# 4. Validar
psql "$RESTORE_CONNECTION_STRING" -c "\dt"
psql "$RESTORE_CONNECTION_STRING" -c "SELECT COUNT(*) FROM registros_lavado;"
```

**Opci√≥n 2: Restore de tablas espec√≠ficas**

```bash
# Solo restaurar tabla de registros
pg_restore \
  --dbname="$RESTORE_CONNECTION_STRING" \
  --table=registros_lavado \
  --verbose \
  backup.dump
```

**Opci√≥n 3: Restore desde SQL plain text**

```bash
# 1. Descargar y desencriptar
openssl enc -d -aes-256-cbc -in backup.sql.gz.enc -out backup.sql.gz \
  -pass pass:$BACKUP_KEY
gunzip backup.sql.gz

# 2. Restaurar
psql "$RESTORE_CONNECTION_STRING" < backup.sql
```

### Estrategia de Promoci√≥n de Branch

Una vez validado el restore:

**Opci√≥n A**: Cambiar connection string en Vercel
```bash
# Actualizar variable de entorno en Vercel
vercel env rm DATABASE_URL production
vercel env add DATABASE_URL production
# (pegar el nuevo connection string del branch restaurado)
```

**Opci√≥n B**: Copiar datos al branch original
```sql
-- Desde el branch restaurado al branch producci√≥n
-- (requiere l√≥gica m√°s compleja, no recomendado)
```

**Opci√≥n C**: Usar branch restaurado como nuevo principal
```bash
# En Neon console:
# 1. Renombrar branch actual ‚Üí "old-production-backup"
# 2. Renombrar branch restaurado ‚Üí "production"
# 3. Actualizar connection string en Vercel si cambi√≥
```

---

## ‚úÖ 5. Checklist de Validaci√≥n Post-Restore

### Validaci√≥n Autom√°tica (Script)

```javascript
// scripts/validate-restore.js

const validateRestoredData = async (connectionString, originalMetadata) => {
  const client = await connectToPostgres(connectionString);
  
  const validations = {
    schema: await validateSchema(client, originalMetadata),
    data: await validateData(client, originalMetadata),
    integrity: await validateIntegrity(client),
    functionality: await validateFunctionality(client)
  };

  return {
    success: Object.values(validations).every(v => v.passed),
    details: validations
  };
};

// 1. Validaci√≥n de Schema
const validateSchema = async (client, metadata) => {
  const checks = [];

  // Verificar que todas las tablas existen
  for (const table of metadata.tables) {
    const exists = await client.query(`
      SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = '${table.name}'
      );
    `);
    checks.push({
      name: `Tabla ${table.name} existe`,
      passed: exists.rows[0].exists
    });
  }

  // Verificar cantidad de tablas
  const tableCount = await client.query(`
    SELECT COUNT(*) FROM information_schema.tables 
    WHERE table_schema = 'public';
  `);
  checks.push({
    name: 'Cantidad de tablas',
    expected: metadata.tables.length,
    actual: parseInt(tableCount.rows[0].count),
    passed: parseInt(tableCount.rows[0].count) === metadata.tables.length
  });

  return { passed: checks.every(c => c.passed), checks };
};

// 2. Validaci√≥n de Datos
const validateData = async (client, metadata) => {
  const checks = [];

  // Verificar row counts por tabla
  for (const table of metadata.tables) {
    const count = await client.query(`SELECT COUNT(*) FROM ${table.name}`);
    const actual = parseInt(count.rows[0].count);
    
    checks.push({
      name: `Registros en ${table.name}`,
      expected: table.row_count,
      actual: actual,
      passed: actual === table.row_count,
      tolerance: Math.abs(actual - table.row_count) <= 5 // Tolerancia de 5 registros
    });
  }

  return { passed: checks.every(c => c.passed || c.tolerance), checks };
};

// 3. Validaci√≥n de Integridad
const validateIntegrity = async (client) => {
  const checks = [];

  // Foreign keys
  const fkCheck = await client.query(`
    SELECT COUNT(*) FROM information_schema.table_constraints 
    WHERE constraint_type = 'FOREIGN KEY';
  `);
  checks.push({
    name: 'Foreign keys presentes',
    actual: parseInt(fkCheck.rows[0].count),
    passed: parseInt(fkCheck.rows[0].count) > 0
  });

  // Indexes
  const indexCheck = await client.query(`
    SELECT COUNT(*) FROM pg_indexes WHERE schemaname = 'public';
  `);
  checks.push({
    name: '√çndices presentes',
    actual: parseInt(indexCheck.rows[0].count),
    passed: parseInt(indexCheck.rows[0].count) > 0
  });

  // Secuencias
  const seqCheck = await client.query(`
    SELECT COUNT(*) FROM information_schema.sequences;
  `);
  checks.push({
    name: 'Secuencias presentes',
    actual: parseInt(seqCheck.rows[0].count),
    passed: parseInt(seqCheck.rows[0].count) > 0
  });

  return { passed: checks.every(c => c.passed), checks };
};

// 4. Validaci√≥n Funcional
const validateFunctionality = async (client) => {
  const checks = [];

  // Test query simple
  try {
    await client.query('SELECT 1');
    checks.push({ name: 'Query b√°sica', passed: true });
  } catch (e) {
    checks.push({ name: 'Query b√°sica', passed: false, error: e.message });
  }

  // Test join entre tablas cr√≠ticas
  try {
    const result = await client.query(`
      SELECT COUNT(*) FROM registros_lavado r
      JOIN clientes c ON r.celular = c.celular
      LIMIT 1;
    `);
    checks.push({ name: 'Join registros-clientes', passed: true });
  } catch (e) {
    checks.push({ name: 'Join registros-clientes', passed: false, error: e.message });
  }

  return { passed: checks.every(c => c.passed), checks };
};
```

### Checklist Manual de Validaci√≥n

**CR√çTICO - Verificar antes de promover a producci√≥n**:

#### 1. Schema
- [ ] Todas las tablas esperadas existen
- [ ] Columnas cr√≠ticas presentes (registros_lavado.id, .patente, .celular)
- [ ] Foreign keys activas
- [ ] √çndices creados
- [ ] Secuencias reiniciadas correctamente

#### 2. Datos
- [ ] Cantidad de registros en `registros_lavado` coincide (~¬±5)
- [ ] Cantidad de registros en `clientes` coincide
- [ ] Cantidad de usuarios coincide
- [ ] √öltimo registro tiene fecha coherente
- [ ] No hay duplicados en `registros_lavado.id`
- [ ] No hay valores NULL en columnas NOT NULL

#### 3. Integridad Referencial
- [ ] Todos los `registros_lavado.celular` existen en `clientes.celular`
- [ ] Todos los `registros_lavado.usuario_id` existen en `usuarios.id`
- [ ] No hay registros hu√©rfanos

#### 4. Funcionalidad
- [ ] Query b√°sica funciona: `SELECT * FROM registros_lavado LIMIT 1`
- [ ] Join funciona: `SELECT r.*, c.nombre FROM registros_lavado r JOIN clientes c ON r.celular = c.celular LIMIT 1`
- [ ] Autenticaci√≥n funciona (usuarios pueden hacer login)
- [ ] Agregar un registro de prueba funciona
- [ ] Eliminar registro de prueba funciona

#### 5. Performance
- [ ] √çndices funcionando: `EXPLAIN SELECT * FROM registros_lavado WHERE patente = 'ABC123'`
- [ ] Query time razonable (< 100ms para queries simples)

#### 6. Espec√≠fico Multitenant
- [ ] Empresas en branch central existen
- [ ] Branch URLs en `empresas` tabla son v√°lidos
- [ ] Cada empresa tiene su configuraci√≥n (listas_precios, tipos_vehiculo)

### Queries de Validaci√≥n Manual

```sql
-- 1. Verificar estructura de tablas
\dt

-- 2. Verificar row counts
SELECT 
  'registros_lavado' as tabla, COUNT(*) as registros FROM registros_lavado
UNION ALL
SELECT 'clientes', COUNT(*) FROM clientes
UNION ALL
SELECT 'usuarios', COUNT(*) FROM usuarios
UNION ALL
SELECT 'empresas', COUNT(*) FROM empresas
UNION ALL
SELECT 'listas_precios', COUNT(*) FROM listas_precios;

-- 3. Verificar integridad referencial
SELECT COUNT(*) as registros_huerfanos
FROM registros_lavado r
LEFT JOIN clientes c ON r.celular = c.celular
WHERE c.celular IS NULL;

-- Deber√≠a dar 0

-- 4. Verificar √∫ltimo registro (fecha coherente)
SELECT * FROM registros_lavado 
ORDER BY fecha_hora DESC 
LIMIT 5;

-- 5. Verificar usuarios pueden autenticar
SELECT id, username, email, rol 
FROM usuarios 
WHERE username = 'admin';

-- 6. Verificar √≠ndices
SELECT 
  schemaname,
  tablename,
  indexname,
  indexdef
FROM pg_indexes
WHERE schemaname = 'public'
ORDER BY tablename, indexname;

-- 7. Verificar foreign keys
SELECT
  tc.table_name, 
  kcu.column_name,
  ccu.table_name AS foreign_table_name,
  ccu.column_name AS foreign_column_name
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
  ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
  ON ccu.constraint_name = tc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY';

-- 8. Verificar secuencias
SELECT 
  sequencename,
  last_value,
  increment_by
FROM pg_sequences
WHERE schemaname = 'public';
```

---

## üö® Procedimiento de Rollback

Si el restore falla o la validaci√≥n no pasa:

### Rollback Seguro

```javascript
// scripts/rollback-restore.js

const rollbackRestore = async (restoreBranchId) => {
  console.log(`‚ö†Ô∏è Iniciando rollback de restore en branch ${restoreBranchId}`);

  // 1. Verificar que branch de producci√≥n original sigue activo
  const prodBranch = await getNeonBranch('production');
  if (!prodBranch.active) {
    throw new Error('‚ùå Branch de producci√≥n no est√° activo - CR√çTICO');
  }

  // 2. Verificar que Vercel apunta al branch correcto
  const vercelEnv = await getVercelEnv('DATABASE_URL');
  if (vercelEnv !== prodBranch.connection_uri) {
    console.log('‚ö†Ô∏è Vercel no apunta a producci√≥n - restaurando...');
    await setVercelEnv('DATABASE_URL', prodBranch.connection_uri);
  }

  // 3. Eliminar branch de restore fallido
  await deleteNeonBranch(restoreBranchId);
  console.log(`‚úÖ Branch ${restoreBranchId} eliminado`);

  // 4. Validar que producci√≥n funciona
  const validation = await validateProductionHealth(prodBranch.connection_uri);
  if (!validation.healthy) {
    throw new Error('‚ùå Producci√≥n no est√° saludable post-rollback - ALERTA');
  }

  console.log(`‚úÖ Rollback completado - sistema en estado original`);
};
```

---

## üìä Monitoreo y Alertas

### M√©tricas Clave

| M√©trica | Objetivo | Alerta si |
|---------|----------|-----------|
| Duraci√≥n de backup | < 5 min | > 10 min |
| Tama√±o de backup | Crecimiento gradual | Aumento >50% s√∫bito |
| √âxito de backup | 100% | Fallo 2 d√≠as consecutivos |
| Espacio en Drive | < 50% usado | > 80% usado |
| Validaci√≥n post-backup | 100% pass | Cualquier check falla |

### Logs Requeridos

Cada backup debe generar log con:
- Timestamp inicio y fin
- Duraci√≥n total
- Tama√±o del backup
- Cantidad de tablas exportadas
- Row counts por tabla cr√≠tica
- Checksum del archivo
- √âxito/fallo del upload a Drive
- Cualquier warning o error

**Formato de log**:
```json
{
  "backup_id": "lavapp_2026-02-09_03-00",
  "status": "success",
  "started_at": "2026-02-09T03:00:00Z",
  "completed_at": "2026-02-09T03:04:23Z",
  "duration_seconds": 263,
  "database": "lavapp",
  "size_uncompressed": 104857600,
  "size_compressed": 20971520,
  "compression_ratio": 0.20,
  "tables_backed_up": 15,
  "critical_tables": {
    "registros_lavado": 1523,
    "clientes": 234,
    "usuarios": 5
  },
  "checksum": "sha256:abc123...",
  "uploaded_to_drive": true,
  "drive_file_id": "1ABC...XYZ",
  "warnings": [],
  "errors": []
}
```

---

## üîê Seguridad

### Encriptaci√≥n

**Algoritmo**: AES-256-CBC

**Keys**:
- Key principal en Vercel Environment Variable: `BACKUP_ENCRYPTION_KEY`
- Key rotation cada 6 meses
- Keys antiguas guardadas para restore de backups viejos

**Comando de encriptaci√≥n**:
```bash
openssl enc -aes-256-cbc -salt \
  -in backup.dump.gz \
  -out backup.dump.gz.enc \
  -pass pass:$BACKUP_ENCRYPTION_KEY
```

**Comando de desencriptaci√≥n**:
```bash
openssl enc -d -aes-256-cbc \
  -in backup.dump.gz.enc \
  -out backup.dump.gz \
  -pass pass:$BACKUP_ENCRYPTION_KEY
```

### Autenticaci√≥n Google Drive

**M√©todo**: Service Account (no requiere interacci√≥n humana)

**Setup**:
1. Crear proyecto en Google Cloud Console
2. Habilitar Google Drive API
3. Crear Service Account
4. Descargar JSON de credenciales
5. Compartir folder de backups con email del service account
6. Guardar credentials en Vercel Environment Variables

**Permisos requeridos**:
- `https://www.googleapis.com/auth/drive.file` (solo archivos creados por la app)

---

## üéØ Implementaci√≥n en Fases

### Fase 1: MVP (1-2 d√≠as)
- [ ] Script b√°sico de backup (pg_dump)
- [ ] Upload manual a Google Drive
- [ ] Metadata JSON
- [ ] Testing de restore manual

### Fase 2: Automatizaci√≥n (2-3 d√≠as)
- [ ] Integraci√≥n con Google Drive API
- [ ] Vercel Cron Job para backups diarios
- [ ] Encriptaci√≥n
- [ ] Logs estructurados

### Fase 3: Validaci√≥n (1-2 d√≠as)
- [ ] Script de validaci√≥n post-backup
- [ ] Script de restore automatizado
- [ ] Checklist de validaci√≥n
- [ ] Testing en branch de restore

### Fase 4: Producci√≥n (1 d√≠a)
- [ ] Pol√≠tica de retenci√≥n implementada
- [ ] Monitoreo y alertas
- [ ] Documentaci√≥n completa
- [ ] Runbook de emergencia

---

## üìù Comandos R√°pidos de Referencia

### Backup Manual
```bash
# Full backup de un branch
pg_dump --format=custom --compress=9 \
  "$NEON_CONNECTION_STRING" \
  --file="backup_$(date +%Y-%m-%d).dump"
```

### Restore Manual
```bash
# Crear branch en Neon UI primero, luego:
pg_restore \
  --dbname="$RESTORE_CONNECTION_STRING" \
  --verbose --clean --if-exists \
  backup_2026-02-09.dump
```

### Validar Backup
```bash
# Listar contenido sin restaurar
pg_restore --list backup.dump | head -20
```

### Checksum
```bash
# Generar checksum
sha256sum backup.dump > backup.dump.sha256

# Verificar checksum
sha256sum -c backup.dump.sha256
```

---

## ‚ùì FAQ - Preguntas Frecuentes

### ¬øPor qu√© no usar Neon's built-in backups?

**Respuesta**: Plan Free de Neon NO incluye backups autom√°ticos. Solo Plan Launch ($19/mes) tiene PITR. Este sistema es para mantener $0 de costo recurrente.

### ¬øPor qu√© Google Drive y no AWS S3?

**Respuesta**: 
- Google Drive: 15 GB gratis, suficiente para a√±os
- AWS S3: Cuesta dinero ($0.023/GB/mes + requests)
- Si el proyecto crece, pod√©s migrar a S3 f√°cilmente

### ¬øQu√© pasa si Google Drive se llena?

**Respuesta**: Con la pol√≠tica de retenci√≥n (30 d√≠as + 3 meses + 1 a√±o), us√°s ~3-4 GB. Si se llena:
1. Ajustar retenci√≥n (e.g., 15 d√≠as en vez de 30)
2. Comprar Google One ($2/mes por 100GB)
3. Migrar a otro storage (S3, Backblaze)

### ¬øPuedo restaurar solo una tabla?

**Respuesta**: S√≠, con custom format:
```bash
pg_restore --table=registros_lavado backup.dump
```

### ¬øCu√°nto tarda un restore completo?

**Respuesta**: 
- Descargar de Drive: 1-2 min (para 20MB)
- Crear branch Neon: 30-60 seg
- Restore pg_restore: 2-5 min (depende de tama√±o)
- Validaci√≥n: 1-2 min
- **Total**: 5-10 minutos

### ¬øQu√© pasa si falla un backup autom√°tico?

**Respuesta**: El script deber√≠a:
1. Reintentar 3 veces con delay
2. Si sigue fallando, enviar alerta (email/Slack)
3. Logging detallado del error
4. No sobrescribir √∫ltimo backup exitoso

### ¬øC√≥mo pruebo que el backup funciona?

**Respuesta**: Monthly drill:
1. Tomar backup de producci√≥n
2. Crear branch de test
3. Restaurar en branch de test
4. Ejecutar checklist de validaci√≥n
5. Eliminar branch de test
6. Documentar resultado

---

## üéØ Pr√≥ximos Pasos

Una vez aprobado este dise√±o:

1. [ ] Crear Service Account de Google Cloud
2. [ ] Crear script `scripts/backup-to-drive.js`
3. [ ] Crear script `scripts/restore-from-drive.js`
4. [ ] Crear script `scripts/validate-restore.js`
5. [ ] Configurar Vercel Cron Job
6. [ ] Testing completo en staging
7. [ ] Primer backup manual de producci√≥n
8. [ ] Restore drill en branch de test
9. [ ] Documentar runbook de emergencia
10. [ ] Activar backups autom√°ticos

**Tiempo estimado total**: 5-7 d√≠as de desarrollo + testing

---

## üìö Referencias

- [PostgreSQL pg_dump docs](https://www.postgresql.org/docs/current/app-pgdump.html)
- [PostgreSQL pg_restore docs](https://www.postgresql.org/docs/current/app-pgrestore.html)
- [Google Drive API v3](https://developers.google.com/drive/api/v3/about-sdk)
- [Neon Branching Guide](https://neon.tech/docs/guides/branching)
- [Vercel Cron Jobs](https://vercel.com/docs/cron-jobs)

---

**Documento creado**: 2026-02-09  
**Autor**: Sistema de Backup LAVAPP  
**Versi√≥n**: 1.0.0  
**Estado**: Pendiente aprobaci√≥n
